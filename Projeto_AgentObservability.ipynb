{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxXAB/JtaXEOF0V0KsYhuE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guitsuo/projectobservability/blob/main/Projeto_AgentObservability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKnM_bjkpPKJ",
        "outputId": "26daa51b-6651-4170-b63d-fed0bc253832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"candidates\": [\n",
            "    {\n",
            "      \"content\": {\n",
            "        \"parts\": [\n",
            "          {\n",
            "            \"text\": \"Alright, let's break down how AI works.  It's a vast field, but we can cover the core concepts to give you a good understanding.  Think of AI as trying to mimic human intelligence using computers.  It's not about creating robots that are exactly like humans, but rather about enabling machines to perform tasks that typically require human intelligence.\\n\\nHere's a breakdown of the key ideas:\\n\\n**1.  The Core Concept: Learning from Data**\\n\\n   The fundamental idea behind most modern AI is that machines learn from data. Instead of being explicitly programmed for every possible situation, they are given a large dataset and trained to identify patterns, relationships, and rules within that data.  This allows them to make predictions, decisions, or perform actions without being specifically told how to do so in every circumstance.\\n\\n**2.  Types of AI (A simplified view):**\\n\\n   *   **Narrow or Weak AI (Most Current AI):**  Designed for a specific task. Think of spam filters, recommendation systems (like Netflix or Amazon), voice assistants (Siri, Alexa), or image recognition software. They are excellent at their designated task, but they don't possess general intelligence.  This is where most AI research and applications currently reside.\\n\\n   *   **General or Strong AI (Hypothetical):**  Possesses human-level intelligence. It could understand, learn, and apply knowledge across a wide range of tasks, just like a human.  This is still largely theoretical and hasn't been achieved.\\n\\n   *   **Super AI (Hypothetical):**  An AI that surpasses human intelligence in all aspects.  This is often depicted in science fiction and raises significant ethical considerations.\\n\\n**3.  Key Techniques & Technologies:**\\n\\n   *   **Machine Learning (ML):** The most popular approach to AI right now. It's a set of techniques that allows computers to learn from data *without* being explicitly programmed.\\n\\n        *   **Supervised Learning:**  The algorithm is trained on a labeled dataset (i.e., data where the correct answer is already known). Think of training an image recognition system to identify cats. You provide the system with thousands of images, each labeled as \\\"cat\\\" or \\\"not cat.\\\" The algorithm learns to associate features (e.g., pointy ears, whiskers) with the \\\"cat\\\" label.\\n            *   **Examples:** Image Classification, Spam Filtering, Regression (predicting a value based on other values)\\n\\n        *   **Unsupervised Learning:**  The algorithm is trained on an unlabeled dataset.  The goal is to find hidden patterns or structures within the data.  Think of grouping customers into different segments based on their purchasing behavior. The algorithm identifies clusters of customers with similar characteristics without being told what those clusters should be.\\n            *   **Examples:** Clustering, Anomaly Detection, Dimensionality Reduction\\n\\n        *   **Reinforcement Learning:**  The algorithm learns through trial and error by interacting with an environment and receiving rewards or penalties for its actions. Think of training a computer to play a game.  The algorithm tries different strategies and learns which actions lead to higher scores (rewards) and which lead to lower scores (penalties).\\n            *   **Examples:** Game playing (e.g., AlphaGo), Robotics, Control Systems\\n\\n   *   **Deep Learning (DL):** A subfield of machine learning that uses artificial neural networks with many layers (hence \\\"deep\\\").  These networks can learn very complex patterns from large amounts of data. Deep learning is particularly effective in areas like image recognition, natural language processing, and speech recognition.\\n\\n        *   **Neural Networks:** Inspired by the structure of the human brain, neural networks consist of interconnected nodes (neurons) that process and transmit information.  Each connection has a weight associated with it, which is adjusted during training to improve the network's accuracy. The \\\"depth\\\" refers to the number of layers of neurons in the network. More layers allow for more complex patterns to be learned.\\n        *   **Convolutional Neural Networks (CNNs):** Specifically designed for processing images.\\n        *   **Recurrent Neural Networks (RNNs):**  Well-suited for processing sequential data like text or time series.\\n\\n   *   **Natural Language Processing (NLP):**  Focuses on enabling computers to understand, interpret, and generate human language.  This includes tasks like:\\n\\n        *   **Text analysis:**  Extracting information from text.\\n        *   **Machine translation:** Translating text from one language to another.\\n        *   **Chatbots:**  Creating conversational agents.\\n        *   **Sentiment analysis:**  Determining the emotional tone of text.\\n\\n   *   **Computer Vision:** Enables computers to \\\"see\\\" and interpret images and videos.  This includes tasks like:\\n\\n        *   **Object detection:**  Identifying objects in an image.\\n        *   **Image recognition:**  Classifying images.\\n        *   **Image segmentation:**  Dividing an image into regions.\\n\\n   *   **Robotics:**  Combines AI with physical robots to create systems that can perform tasks in the real world.\\n\\n**4.  The Training Process (Simplified):**\\n\\n   1.  **Data Collection:** Gather a large dataset relevant to the task you want the AI to perform. The quality and quantity of data are crucial.  \\\"Garbage in, garbage out\\\" applies here.\\n   2.  **Data Preprocessing:** Clean and prepare the data. This may involve handling missing values, removing noise, and transforming the data into a suitable format.\\n   3.  **Model Selection:** Choose an appropriate AI model based on the type of problem and the characteristics of the data. (e.g., a neural network for image recognition, a decision tree for classification).\\n   4.  **Training:** Feed the data to the model and allow it to learn the underlying patterns.  During training, the model adjusts its internal parameters (e.g., weights in a neural network) to minimize errors and improve its accuracy.  This often involves an iterative process, where the model is repeatedly exposed to the data until it reaches a desired level of performance.\\n   5.  **Validation & Testing:**  Evaluate the model's performance on a separate dataset that it hasn't seen before. This helps to ensure that the model generalizes well to new data and avoids overfitting (i.e., memorizing the training data instead of learning the underlying patterns).\\n   6.  **Deployment:**  Deploy the trained model into a real-world application.\\n   7.  **Monitoring & Maintenance:** Continuously monitor the model's performance and retrain it periodically with new data to maintain its accuracy and relevance.\\n\\n**5.  Example: Image Recognition (Cat vs. Not Cat)**\\n\\n   1.  **Data:** A large dataset of images, each labeled as either \\\"cat\\\" or \\\"not cat.\\\"\\n   2.  **Model:**  A convolutional neural network (CNN)\\n   3.  **Training:** The CNN is fed the images.  It analyzes the pixel patterns and learns to associate certain features with the \\\"cat\\\" label. For example, it might learn that cats often have pointy ears, whiskers, and a certain fur texture. The network adjusts its internal parameters (weights) to improve its ability to correctly classify images as \\\"cat\\\" or \\\"not cat.\\\"\\n   4.  **Testing:** After training, the CNN is tested on a new set of images that it hasn't seen before. The accuracy of the model is measured to assess how well it generalizes to new data.\\n   5.  **Deployment:** The trained CNN can then be deployed in an application, such as a mobile app that can identify cats in photos.\\n\\n**6. Important Considerations:**\\n\\n   *   **Data Bias:** AI models are only as good as the data they are trained on. If the data is biased (e.g., contains more images of male faces than female faces), the model may exhibit biased behavior.  This is a major concern in AI ethics.\\n   *   **Explainability:**  Some AI models (especially deep learning models) are very complex and difficult to understand.  This can make it challenging to debug them or to trust their predictions.  \\\"Explainable AI\\\" (XAI) is an area of research focused on making AI models more transparent and understandable.\\n   *   **Ethics:**  AI raises a number of ethical concerns, including bias, fairness, privacy, security, and the potential for job displacement. It's important to develop and use AI responsibly and ethically.\\n   *   **Computational Resources:** Training large AI models often requires significant computational resources, including powerful GPUs and large amounts of memory.  Cloud computing platforms provide access to these resources.\\n\\n**In Summary:**\\n\\nAI is a powerful technology that has the potential to transform many aspects of our lives. It works by enabling machines to learn from data, identify patterns, and make predictions or decisions without being explicitly programmed for every possible situation.  Machine learning, particularly deep learning, is a central component of modern AI.  However, it's important to be aware of the potential limitations and ethical considerations associated with AI.\\n\"\n",
            "          }\n",
            "        ],\n",
            "        \"role\": \"model\"\n",
            "      },\n",
            "      \"finishReason\": \"STOP\",\n",
            "      \"citationMetadata\": {\n",
            "        \"citationSources\": [\n",
            "          {\n",
            "            \"startIndex\": 2880,\n",
            "            \"endIndex\": 3004,\n",
            "            \"uri\": \"https://github.com/NimmyBibin/ML-Assignments\"\n",
            "          },\n",
            "          {\n",
            "            \"startIndex\": 2921,\n",
            "            \"endIndex\": 3057\n",
            "          },\n",
            "          {\n",
            "            \"startIndex\": 3663,\n",
            "            \"endIndex\": 3821\n",
            "          },\n",
            "          {\n",
            "            \"startIndex\": 4302,\n",
            "            \"endIndex\": 4432\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      \"avgLogprobs\": -0.28745351277520842\n",
            "    }\n",
            "  ],\n",
            "  \"usageMetadata\": {\n",
            "    \"promptTokenCount\": 4,\n",
            "    \"candidatesTokenCount\": 1919,\n",
            "    \"totalTokenCount\": 1923,\n",
            "    \"promptTokensDetails\": [\n",
            "      {\n",
            "        \"modality\": \"TEXT\",\n",
            "        \"tokenCount\": 4\n",
            "      }\n",
            "    ],\n",
            "    \"candidatesTokensDetails\": [\n",
            "      {\n",
            "        \"modality\": \"TEXT\",\n",
            "        \"tokenCount\": 1919\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  \"modelVersion\": \"gemini-2.0-flash\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "!curl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyBLv4MZ7i18ajOAzn_i90AtPY3itNeIu3U\" -H 'Content-Type: application/json' -X POST -d '{\"contents\": [{\"parts\": [{\"text\": \"Explain how AI works\"}]}]}'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install phoenix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOsmcPTAvXUf",
        "outputId": "f2a54f15-4fa9-4c59-80a0-178d756ce9f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting phoenix\n",
            "  Downloading phoenix-0.9.1.zip (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: phoenix\n",
            "  Building wheel for phoenix (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for phoenix: filename=phoenix-0.9.1-py3-none-any.whl size=4820 sha256=4b9f3da1988bb150dfbd32097a7f083926b0472ee51d8bc459bd0e2a1d3714b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/e2/dc/84bc45598c0c16632ec0ea1f6fb2bdf379b60c286938b23591\n",
            "Successfully built phoenix\n",
            "Installing collected packages: phoenix\n",
            "Successfully installed phoenix-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import phoenix as px\n",
        "import os"
      ],
      "metadata": {
        "id": "lQZBKfvjvcMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "KpIKxnVfvryi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=\"AIzaSyBLv4MZ7i18ajOAzn_i90AtPY3itNeIu3U\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=\"Explain how AI works\",\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZmzwtUupP7B",
        "outputId": "9cf4f50b-c6c8-4a0d-8dac-b26621eab493"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:502: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, let's break down how AI (Artificial Intelligence) works, aiming for clarity and understanding. We'll cover the fundamental concepts without getting overly technical right away.\n",
            "\n",
            "**Core Idea:  Making Machines Think (Sort Of)**\n",
            "\n",
            "At its heart, AI is about creating machines that can perform tasks that typically require human intelligence.  These tasks can include:\n",
            "\n",
            "*   **Learning:**  Improving performance over time based on data.\n",
            "*   **Problem-solving:** Figuring out how to achieve a goal given certain constraints.\n",
            "*   **Reasoning:**  Drawing conclusions from information.\n",
            "*   **Perception:**  Understanding the world through senses (like vision, hearing, etc.).\n",
            "*   **Natural Language Processing (NLP):** Understanding and generating human language.\n",
            "\n",
            "**The Foundation: Algorithms and Data**\n",
            "\n",
            "AI systems are built upon two main pillars:\n",
            "\n",
            "1.  **Algorithms:** These are sets of instructions or rules that a computer follows to solve a specific problem.  Think of them like recipes for intelligence.\n",
            "2.  **Data:** AI algorithms need data to learn from.  The more relevant and high-quality data, the better the AI system will generally perform.\n",
            "\n",
            "**Key Types of AI Approaches**\n",
            "\n",
            "There are several different approaches to achieving AI, but here are some of the most important:\n",
            "\n",
            "*   **Machine Learning (ML):**  This is the most common type of AI in use today. Instead of explicitly programming a machine to do something, we *train* it using data.  The machine learns patterns and relationships in the data and uses those patterns to make predictions or decisions on new, unseen data.\n",
            "\n",
            "    *   **Supervised Learning:**  The algorithm is trained on a labeled dataset. This means that for each input, we also provide the correct output (the \"label\"). The algorithm learns to map inputs to outputs.  *Example:  Training a spam filter. You give it emails labeled as \"spam\" or \"not spam,\" and it learns to identify spam emails.*\n",
            "\n",
            "    *   **Unsupervised Learning:** The algorithm is trained on an unlabeled dataset. It has to find patterns and structures in the data on its own. *Example:  Clustering customers into different groups based on their purchasing behavior.*\n",
            "\n",
            "    *   **Reinforcement Learning:** The algorithm learns by interacting with an environment and receiving rewards or penalties for its actions.  It learns to make decisions that maximize its cumulative reward. *Example:  Training a computer to play a game like chess or Go.*\n",
            "\n",
            "*   **Deep Learning (DL):**  A subfield of machine learning that uses artificial neural networks with many layers (hence \"deep\").  Deep learning is particularly good at handling complex data like images, audio, and text.\n",
            "\n",
            "    *   **Neural Networks:** Inspired by the structure of the human brain, neural networks consist of interconnected nodes (neurons) that process information. The connections between neurons have weights that are adjusted during the learning process.  The more layers, the more complex patterns it can learn.  *Example:  Image recognition, natural language processing, speech recognition.*\n",
            "\n",
            "*   **Rule-Based Systems (Expert Systems):**  These systems use a set of predefined rules to make decisions.  A human expert defines the rules, and the system applies them to new situations.  *Example:  A medical diagnosis system that uses rules to suggest possible diagnoses based on a patient's symptoms.*  This is an older approach and less flexible than machine learning.\n",
            "\n",
            "**How Machine Learning Works: A Simplified Example (Supervised Learning)**\n",
            "\n",
            "Let's say you want to build an AI system to predict the price of a house based on its size.\n",
            "\n",
            "1.  **Collect Data:** You gather a dataset of houses, including their size (in square feet) and their corresponding prices.  This is your \"training data.\"\n",
            "\n",
            "2.  **Choose an Algorithm:** You select a supervised learning algorithm, like linear regression.  Linear regression tries to find a line (in this case, a straight line) that best fits the relationship between size and price.\n",
            "\n",
            "3.  **Train the Model:** You feed the training data into the algorithm. The algorithm adjusts the parameters of the linear regression model (the slope and intercept of the line) to minimize the difference between the predicted prices and the actual prices in the training data.  This is the \"learning\" process.\n",
            "\n",
            "4.  **Test the Model:**  You use a separate set of data (the \"testing data\") to evaluate how well the model generalizes to new, unseen data.  You compare the model's predictions to the actual prices in the testing data.\n",
            "\n",
            "5.  **Make Predictions:** Once you're satisfied with the model's performance, you can use it to predict the price of a new house based on its size.\n",
            "\n",
            "**Deep Learning in a bit more detail**\n",
            "\n",
            "Deep learning uses artificial neural networks with many layers.  Each layer extracts features from the data, and subsequent layers combine those features to learn more complex representations.\n",
            "\n",
            "Imagine trying to teach a computer to recognize cats in images:\n",
            "\n",
            "1.  **Input Layer:** The image is fed into the input layer of the neural network.\n",
            "\n",
            "2.  **Hidden Layers:**\n",
            "    *   The first hidden layer might detect edges and corners in the image.\n",
            "    *   The second hidden layer might combine those edges and corners to detect simple shapes like circles and lines.\n",
            "    *   Subsequent layers might combine these shapes to detect parts of a cat, like ears, eyes, and noses.\n",
            "    *   Finally, a later layer might combine all these features to recognize a cat.\n",
            "\n",
            "3.  **Output Layer:** The output layer outputs the probability that the image contains a cat.\n",
            "\n",
            "**The AI Development Process**\n",
            "\n",
            "Developing an AI system typically involves these steps:\n",
            "\n",
            "1.  **Define the Problem:** What specific problem are you trying to solve with AI?\n",
            "2.  **Gather Data:** Collect and prepare the data that the AI system will learn from.  Data cleaning and preprocessing are crucial.\n",
            "3.  **Choose an Algorithm:** Select the appropriate AI algorithm based on the problem and the data.\n",
            "4.  **Train the Model:** Train the AI model using the training data.\n",
            "5.  **Evaluate the Model:** Evaluate the model's performance using testing data.\n",
            "6.  **Tune the Model:** Adjust the model's parameters and hyperparameters to improve its performance.  This is an iterative process.\n",
            "7.  **Deploy the Model:** Deploy the trained model into a real-world application.\n",
            "8.  **Monitor and Maintain:** Continuously monitor the model's performance and retrain it as needed to maintain its accuracy and effectiveness.\n",
            "\n",
            "**Challenges and Limitations**\n",
            "\n",
            "*   **Data Requirements:** AI, especially deep learning, often requires massive amounts of data.\n",
            "*   **Bias:** AI systems can perpetuate and amplify biases present in the training data.  This can lead to unfair or discriminatory outcomes.\n",
            "*   **Explainability:**  Deep learning models can be difficult to understand. It's often hard to know why a model made a particular decision. This is known as the \"black box\" problem.\n",
            "*   **Overfitting:**  A model can become too specialized to the training data and perform poorly on new data.\n",
            "*   **Ethical Considerations:**  AI raises many ethical concerns, such as job displacement, privacy, and the potential for misuse.\n",
            "\n",
            "**In Summary**\n",
            "\n",
            "AI is a broad field encompassing various techniques aimed at creating machines that can perform tasks requiring human intelligence.  Machine learning, especially deep learning, is a dominant approach that relies on training algorithms with data to learn patterns and make predictions. While AI offers tremendous potential, it's important to be aware of its limitations and ethical considerations.\n",
            "\n",
            "I hope this explanation helps!  Let me know if you have any more questions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZOp0PqR8rkM9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}